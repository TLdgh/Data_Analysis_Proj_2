---
title: |
  | \vspace{-4em}MAT5314 Project 2: Bayesian Analysis
author: 
  - Teng Li(7373086)
  - Shiya Gao(300381032) 
  - Chuhan Yue(300376046)
  - Yang Lyu(8701121)
output: 
  pdf_document: 
    keep_tex: true
    includes:
      in_header: columns.tex
fontsize: 11pt
header-includes: 
  - \renewcommand{\and}{\\}
  - \usepackage{float}
  - \floatplacement{figure}{H}
bibliography: References.bib
link-citations: yes
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(plotly)
library(tidyverse)
library(kableExtra)
library(htmlwidgets)
library(webshot)
source("CodeSpace.R")
source("TestSpace.R")
```

# Introduction
An webpage designer might be interested in the goodness of the new design compared with the old one. In this project we were given a data set from a designed experiment. In this experiment, participants were randomly given a new webpage as the treatment or an old webpage as a control. Each participant decides if he/she wants to "convert", or in other words to make a decision. In addition, we treat each visitor's decision as independent. The result forms a random sample of Bernoulli trials. Suppose $X_1,...,X_n$ are the random sample of the visitor's choice, with $X_i=1$ if a visitor chooses to convert to the webpage assigned to him with probability $p$, otherwise $X_i=0$ with probability $1-p$. The success rate $p$ is the parameter of the Bernoulli distribution. Our goal is therefore to compare the success probabilities $p_1$ and $p_2$, where $p_1$ is the rate for the control group and $p_2$ is the rate for the treatment group.

We can have various hypothesis tests on the success probability $p$. One may consider a hypothesis test:

$$
H_0: ~ p_1 \leq p_2 \\
H_1: ~ p_1 > p_2
$$

such that we would like to know if the conversion rate for the old page is greater than the one for the new page. With Bayesian analysis one can evaluate directly the probability of the null and the alternative hypotheses. We can do this by using the Monte Carlo method to evaluate the following integral:

$$
P(p_1 > p_2 |\vec{x}) = \int_0^1 \int_0^1 \mathbb{I}(p_1 > p_2 |\vec{x}) \cdot f(p_1|\vec{x})f(p_2|\vec{x})dp_1 dp_2 = E[\mathbb{I}(p_1 > p_2 |\vec{x})]
$$

where $\mathbb{I}(p_1 \leq p_2|\vec{x})$ is the indicator function given the data and $f(p_1|\vec{x})$, $f(p_2|\vec{x})$ are the posterior Beta probability density functions for control and treatment respectively. To estimate this probability, one only needs to simulate pairs of Beta random variables from the two posterior distributions simultaneously, and calculate the average of the indicator function. 

The interpretation of a confidence interval is important. In a frequentist point of view, our unknown parameter $p$ is a true but fixed value. The confidence interval on the other hand is a random set, thus it is incorrect to state that we are 99% sure that the confidence interval covers the unknown true parameter. It is also incorrect to say that the unknown parameter falls within the confidence interval 99% of the time, because in this statement the unknown parameter is falsely treated as a random variable. Therefore the appropriate interpretation of the confidence interval is: when the experiment is repeated many times to generate random samples and their perspective confidence intervals, 99% of these confidence intervals will cover the unknown fixed parameter.

If we use the Bayesian approach to gain a different understanding of our unknown parameter and to draw inference on it, we then get the ($1-\alpha$)-level credible interval for the conversion rate based on the quantile of the posterior distribution as $[L(\vec{x}), R(\vec{x})]$ such that:
$$
\mathbb{P}(\textbf{p} \in [L(\vec{x}), R(\vec{x})] |\vec{x}) = \int_{L(\vec{x})}^{R(\vec{x})} f(p|\vec{x})dp = 1-\alpha
$$

With such definition, it is perfectly fine to interpret the credible interval as: the probability that our success rate falls within the given credible interval is (1-$\alpha$)%. 

Suppose we assume $Beta(\alpha, \beta)$ is the prior distribution of the success rate p. The prior density function is:
$$
f(p; \alpha,\beta) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} p^{\alpha-1} (1-p)^{\beta-1}, ~ p\in (0,1)
$$
We know the expectation and the variance of Beta distribution as:

\begin{gather*}
E(p)= \frac{\alpha}{\alpha+\beta}\\
Var(p)= \frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)}
\end{gather*}

Thus if we assume that the average success rate is $t_1$ with a variance of $t_2$, then we can solve for the parameters of the prior distribution as 
$$
\alpha = - \frac{t_1}{t_2}\cdot (t_1^2-t_1+t_2), \quad \beta=\alpha \cdot \frac{1-t_1}{t_1}.
$$ 

Since the random sample $X_1,...,X_n$ follows Bernoulli(p) distribution, we have a conjugate pair of the prior and posterior distributions, i.e. the posterior distribution is $Beta(\alpha+\sum_{i=1}^n x_i, \beta+n-\sum_{i=1}^n x_i)$ with the mean and variance:

\begin{gather*}
E(p|\vec{x})=\frac{\alpha+\sum_{i=1}^n x_i}{\alpha+\beta+n}\\
Var(p|\vec{x})=\frac{(\alpha+\sum_{i=1}^n x_i)(\beta+n-\sum_{i=1}^n x_i)}{(\alpha+\beta+n)^2(\alpha+\beta+n+1)}
\end{gather*}

One can see that asymptotically when we have a large sample size n, the mean of the posterior distribution approaches to the maximum likelihood estimator $\hat{p} =\frac{1}{n}\sum_{i=1}^n x_i$. Thus the specification of a prior is less important if the sample size is large. This allows us to make a subjective assumption of the success rate based on a probability distribution instead of viewing it as a fixed but unknown number in the frequentist hypothesis test. In the case where $\alpha=\beta=1$, we obtain the non-informative prior $Beta(1,1)$, which is $Uniform([0,1])$ distribution. It's called non-informative because we assume that all p are equally probable. In other words, we no longer put a subjective assumption on $p$.

# Method
```{r}
# Part 1
ab_data<-read.csv("ab_data.csv", header = TRUE)

#cleanning the data
old <- ab_data %>% filter(landing_page == "old_page" & group == "control")
new <- ab_data %>% filter(landing_page == "new_page" & group == "treatment")
old_distinct <- old %>% distinct(old$user_id, .keep_all = TRUE)
new_distinct <- new %>% distinct(new$user_id, .keep_all = TRUE)

# Part 2
mimic3d<-read.csv("mimic3d.csv", header = TRUE)%>%select(-c("insurance", "religion", "marital_status"))%>%na.omit()
train_data<-mimic3d[1:47180,]
test_data<-mimic3d[47181:nrow(mimic3d),]
```

```{r}
#using non-informative priors
my_instance <- BayesianSample$new(old_distinct,new_distinct,rows_per_subset = 1000,
                           alpha_prior_old=1,
                           alpha_prior_new=1,
                           beta_prior_old=1,
                           beta_prior_new=1)

frame0<-my_instance$calculateMean()
ggplot(frame0, aes(x = size, y = value)) +
  geom_point(shape = 16, color = "blue") +
  labs(title = "Scatter Plot Example", x = "X-axis Label", y = "Y-axis Label")

#using informative priors, subset size = 100
my_instance <- BayesianSample$new(old_distinct,new_distinct,rows_per_subset = 1000,
                           alpha_prior_old=2,
                           alpha_prior_new=2,
                           beta_prior_old=20,
                           beta_prior_new=20)

frame1<-my_instance$calculateMean()
ggplot(frame1, aes(x = size, y = value)) +
  geom_point(shape = 16, color = "blue") +
  labs(title = "Scatter Plot Example", x = "X-axis Label", y = "Y-axis Label")

#combine the two plots
combined_plot <- grid.arrange(plot0, plot1, ncol = 2)
print(combined_plot)
```

```{r}
#Mean_old & Mean_new Plot
result_mean <- frame1[, -which(names(frame1) == "value")]

#reorganize into long format
result_long1 <- gather(result_mean, key = "Variable", value = "Mean", posterior_old_mean:posterior_new_mean)

ggplot(result_long1, aes(x = size, y = Mean, color = Variable)) +
  geom_line() +
  labs(title = "Mean Comparison",
       x = "Size",
       y = "Mean") +
  scale_color_manual(values = c("posterior_old_mean" = "blue", "posterior_new_mean" = "red"))
```

```{r}
# Plot Credible Interval
my_instance$PlotCI()%>%print()
```

```{r}
#Bayesian Regression Analysis
RegressionTest<-BayesianRegression$new(train_data, c("LOSdays"), c("NumTransfers"), prior_sigma=c(8,10), prior_beta=list(m=c(0,0), V=matrix(c(10,3,4,6), nrow=2, byrow = TRUE)) )
RegressionTest$PosteriorPlot()%>%print()
RegressionTest$PredictionPlot(test_data)%>%print()
```


# References